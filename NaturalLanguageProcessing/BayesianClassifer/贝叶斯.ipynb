{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b7790f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 调包实现贝叶斯分类器完成二分类\n",
    "\n",
    "实验内容：\n",
    "1. 数据预处理（删除异常值如sc_w=0的样本，将标签的四分类改为二分类，0和1归为一类，2和3归为一类）\n",
    "2. 使用GaussianNB、BernoulliNB、MultinomialNB完成手机市场价分类\n",
    "3. 计算各自十折交叉验证的精度、查准率、查全率、F1值\n",
    "4. 根据精度、查准率、查全率、F1值的实际意义以及四个值的对比阐述三个算法在手机市场价分类中的表现对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b363bbb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('../data/mobile_phone/train.csv', delimiter=',')\n",
    "\n",
    "data = data.drop(data[data['sc_w']==0].index)\n",
    "print(len(data[data.sc_w == 0].index.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pre_func(x):\n",
    "    if x==0 or x==1:\n",
    "        return 0\n",
    "    elif x==2 or x==3:\n",
    "        return 1\n",
    "\n",
    "data.price_range = data.price_range.apply(pre_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60eec05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = data.columns\n",
    "features = list(set(features) - {\"price_range\"})\n",
    "X = data[features]\n",
    "y = data.price_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1820, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a66352d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.933551</td>\n",
       "      <td>0.934569</td>\n",
       "      <td>0.934060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.497180</td>\n",
       "      <td>0.576881</td>\n",
       "      <td>0.534074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.809890</td>\n",
       "      <td>0.782394</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>0.820539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model       acc  precision    recall        f1\n",
       "0     GaussianNB  0.933516   0.933551  0.934569  0.934060\n",
       "1    BernoulliNB  0.492857   0.497180  0.576881  0.534074\n",
       "2  MultinomialNB  0.809890   0.782394  0.862595  0.820539"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算十折交叉验证下，GaussianNB、BernoulliNB、MultinomialNB的精度、查准率、查全率、F1值\n",
    "result_data = []\n",
    "models = [(GaussianNB(), \"GaussianNB\"), (BernoulliNB(), \"BernoulliNB\"), (MultinomialNB(), \"MultinomialNB\")]\n",
    "for model, model_name in models:\n",
    "    y_hat = cross_val_predict(model, X, y, cv=10)\n",
    "    acc = accuracy_score(y, y_hat)\n",
    "    precision = precision_score(y, y_hat)\n",
    "    recall = recall_score(y, y_hat)\n",
    "    f1 = f1_score(y, y_hat)\n",
    "    result = [model_name, acc, precision, recall, f1]\n",
    "    result_data.append(result)\n",
    "columns = [\"model\", \"acc\", \"precision\", \"recall\", \"f1\"]\n",
    "pd.DataFrame(data=result_data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7f00a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "表格见上方输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ee680",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 手动实现高斯朴素贝叶斯分类器\n",
    "1. 实现高斯朴素贝叶斯分类器并完成手机市场价分类，数据集采用6：4划分\n",
    "2. 计算模型的查准率，查全率，F1值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e97db3c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "我们要实现一个可以处理连续特征的，服从高斯分布的朴素贝叶斯分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e04b3d3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 符号\n",
    "\n",
    "给定训练集 $T$\n",
    "\n",
    "$$T = \\{(x_1, y_1), (x_2, y_2), ···, (x_N, y_N)\\}$$\n",
    "\n",
    "其中，$x$ 为样本的特征，$y$ 是该样本对应的标记，下标表示对应的是第几个样本，上标表示第几个特征。训练集 $T$ 内一共 $\\vert T \\vert = N$ 个样本。\n",
    "\n",
    "假设我们的任务是处理 $K$ 类分类任务，记类标记分别为 $c_1, c_2, ..., c_k$ 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc770f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 目标\n",
    "\n",
    "我们的目标是对样本进行分类，这里我们用概率的方法，求 $P(Y = c_k \\mid X = x), \\ k = 1, 2, ..., K$ 中最大的那个概率对应的 $k$ 是哪个，也就是，给定样本 $x$ ，模型认为它是哪个类别的概率最大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e006548",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 原理\n",
    "\n",
    "由贝叶斯公式：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    P(Y = c_k \\mid X = x) &= \\frac{P(Y = c_k, X = x)}{P(X = x)} \\\\\n",
    "                  &= \\frac{P(X = x \\mid Y = c_k)P(Y = c_k)}{\\sum_kP(X = x \\mid Y = c_k)P(Y = c_k)} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "这里，我们要求 $K$ 个概率中最大的那个，而这 $K$ 个概率的分母都相同，我们可以忽略分母部分，比较分子部分的大小，也就是比较 **先验概率** $P(Y = c_k)$ 和 **似然** $P(X = x \\mid Y = c_k)$ 的乘积。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb46695",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "通过先验概率分布\n",
    "\n",
    "$$\n",
    "P(Y = c_k), \\ k = 1, 2, ..., K\n",
    "$$\n",
    "\n",
    "和条件概率分布\n",
    "\n",
    "$$\n",
    "P(X = x \\mid Y = c_k) = P(X^{(1)} = x^{(1)}, ···, X^{(n)} = x^{(n)} \\mid Y = c_k), \\ k = 1, 2, ..., K\n",
    "$$\n",
    "\n",
    "我们就可以得到联合概率分布 $P(X = x, Y = c_k)$ 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d2745",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**那么，问题就转化为了，如何求先验概率和似然？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2f01c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. 先验概率 $P(Y = c_k)$ ：\n",
    "\n",
    "先验概率的求解很简单，只要统计训练集中类别 $k$ 出现的概率即可。\n",
    "\n",
    "$$\n",
    "P(Y = c_k) = \\frac{\\mathrm{number} \\ \\mathrm{of}\\ c_k}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe26a91",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. 似然 $P(X = x \\mid Y = c_k)$ ：\n",
    "\n",
    "求解这个条件概率比较复杂，**这里我们要假设特征之间相互独立**，可得\n",
    "\n",
    "$$P(X = x \\mid Y = c_k) = \\prod^n_{j=1}P(X^{(j)}=x^{(j)} \\mid Y = c_k)$$\n",
    "\n",
    "其中， $x^{(j)}$ 表示样本 $x$ 的第 $j$ 个特征。\n",
    "\n",
    "这样，复杂的条件概率就转换为了多个特征条件概率的乘积。v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0171da52",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3. 特征 $j$ 的条件概率 $P(X^{(j)}=x^{(j)} \\mid Y = c_k)$ ：\n",
    "\n",
    "因为我们处理的特征都是连续型特征，一般我们假设这些特征服从正态分布。\n",
    "\n",
    "当 $Y = c_k$ 时，$X^{(j)} = a_{jl}$ 的概率可由下面的公式计算得到：\n",
    "\n",
    "$$\n",
    "P(X^{(j)} = a_{jl} \\mid Y = c_k) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2_{c_k,j}}} \\exp{\\bigg( - \\frac{(a_{jl} - \\mu_{c_k,j})^2}{2 \\sigma^2_{c_k,j}} \\bigg)}\n",
    "$$\n",
    "\n",
    "这里 $\\mu_{c_k,j}$ 和 $\\sigma^2_{c_k,j}$ 分别表示当 $Y = c_k$ 时，第 $j$ 个特征的均值和方差，**这个均值和方差都是通过训练集的样本计算出来的**。\n",
    "\n",
    "因为正态分布只需要两个参数（均值和方差）就可以确定，对于特征 $j$ 我们要估计 $K$ 个类别的均值和方差，所以特征 $j$ 的参数共有 $2K$个。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def2f438",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 综上\n",
    "\n",
    "朴素贝叶斯分类器可以表示为：\n",
    "\n",
    "$$\n",
    "y = \\mathop{\\arg\\max}_{c_k} P(Y = c_k) \\prod_j P(X^{(j)} = x^{(j)} \\mid Y = c_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89d29f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 实现\n",
    "实现的时候会遇到数值问题，在上面的条件概率连乘中，如果有几个概率值很小，它们的连乘就会导致下溢，解决方案就是将其改写为连加的形式。\n",
    "\n",
    "首先，我们的目标是：\n",
    "\n",
    "$$\n",
    "y = \\mathop{\\arg\\max}_{c_k} P(Y = c_k) \\prod_j P(X^{(j)} = x^{(j)} \\mid Y = c_k)\n",
    "$$\n",
    "\n",
    "比较这 $K$ 个数值的大小，然后取最大的那个数对应的 $k$。\n",
    "\n",
    "为了解决可能出现的下溢问题，我们对上面的式子取对数，因为是对 $K$ 项都取对数，不会改变单调性，所以取对数是不影响它们之间的大小关系的。\n",
    "\n",
    "那目标就变成了：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y &= \\mathop{\\arg\\max}_{c_k} \\big[ \\log^{ \\ P(Y = c_k) \\prod_j P(X^{(j)} = x^{(j)} \\mid Y = c_k)} \\big] \\\\\n",
    "&= \\mathop{\\arg\\max}_{c_k} \\big[ \\log^{ \\ P(y = c_k)} + \\sum_j \\log^{ \\ P(X^{(j)} = x^{(j)} \\mid Y = c_k)} \\big]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "在求条件概率的时候，也进行变换：\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\log^{ \\ P(X^{(j)} = x^{(j)} \\mid Y = c_k)} &= \\log^{ \\ \\bigg[\\frac{1}{\\sqrt{2 \\pi \\sigma^2_{c_k,j}}} \\exp{\\bigg(- \\frac{(a_{jl} - \\mu_{c_k,j})^2}{2 \\sigma^2_{c_k,j}}\\bigg)}\\bigg]}\\\\\n",
    "&= \\log^{ \\frac{1}{\\sqrt{2 \\pi \\sigma^2_{c_k,j}}} } + \\log^{ \\exp{\\bigg(- \\frac{(a_{jl} - \\mu_{c_k,j})^2}{2 \\sigma^2_{c_k,j}}\\bigg)} }\\\\\n",
    "&= - \\frac{1}{2} \\log^{2 \\pi \\sigma^2_{c_k,j}} - \\frac{1}{2} \\frac{(a_{jl} - \\mu_{c_k,j})^2}{\\sigma^2_{c_k,j}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "所以，高斯朴素贝叶斯就可以变形为：\n",
    "\n",
    "$$\n",
    "y = \\mathop{\\arg\\max}_{c_k} \\bigg[ \\log^{ \\ P(y = c_k)} + \\sum_j \\big( - \\frac{1}{2} \\log^{2 \\pi \\sigma^2_{c_k,j}} - \\frac{1}{2} \\frac{(a_{jl} - \\mu_{c_k,j})^2}{\\sigma^2_{c_k,j}} \\big) \\bigg]\n",
    "$$\n",
    "\n",
    "上式就是我们需要求的，我们要求出 $K$ 个值，然后求最大的那个对应的 $k$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95792c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**接下来我们开始实现高斯朴素贝叶斯**，我们以类的形式实现这个高斯朴素贝叶斯。因为朴素贝叶斯是懒惰学习，所以这个模型只有在预测的时候，会进行大量的运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f800703b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class myGaussianNB:\n",
    "    '''\n",
    "    处理连续特征的高斯朴素贝叶斯\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化四个字典\n",
    "        self.label_mapping     类标记 与 下标(int)\n",
    "        self.probability_of_y  类标记 与 先验概率(float)\n",
    "        self.mean              类标记 与 均值(np.ndarray)\n",
    "        self.var               类标记 与 方差(np.ndarray)\n",
    "        '''\n",
    "        self.label_mapping = dict()\n",
    "        self.probability_of_y = dict()\n",
    "        self.mean = dict()\n",
    "        self.var = dict()\n",
    "        \n",
    "    def _clear(self):\n",
    "        '''\n",
    "        为了防止一个实例反复的调用fit方法，我们需要每次调用fit前，将之前学习到的参数删除掉\n",
    "        '''\n",
    "        self.label_mapping.clear()\n",
    "        self.probability_of_y.clear()\n",
    "        self.mean.clear()\n",
    "        self.var.clear()\n",
    "    \n",
    "    def fit(self, trainX, trainY):\n",
    "        '''\n",
    "        这里，我们要根据trainY内的类标记，针对每类，计算这类的先验概率，以及这类训练样本每个特征的均值和方差\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            trainX: np.ndarray, 训练样本的特征, 维度：(样本数, 特征数)\n",
    "        \n",
    "            trainY: np.ndarray, 训练样本的标记, 维度：(样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 先调用_clear\n",
    "        self._clear()\n",
    "        \n",
    "        # 获取类标记\n",
    "        labels = np.unique(trainY)\n",
    "        \n",
    "        # 添加类标记与下标的映射关系\n",
    "        self.label_mapping = {label: index for index, label in enumerate(labels)}\n",
    "        \n",
    "        # 遍历每个类\n",
    "        for label in labels:\n",
    "            \n",
    "            # 取出为label这类的所有训练样本，存为 x\n",
    "            x = trainX[trainY == label]\n",
    "            x = x.to_numpy()\n",
    "            \n",
    "            # 计算先验概率，用 x 的样本个数除以训练样本总个数，存储到 self.probability_of_y 中，键为 label，值为先验概率\n",
    "            \n",
    "            self.probability_of_y[label] = len(x) / len(trainY)\n",
    "            \n",
    "            # 对 x 的每列求均值，使用 keepdims = True 保持维度，存储到 self.mean 中，键为 label，值为每列的均值组成的一个二维 np.ndarray\n",
    "            # YOUR CODE HERE\n",
    "            self.mean[label] = np.mean(x, axis=0, keepdims=True)\n",
    "            # print(self.mean[label].shape)\n",
    "            \n",
    "            \n",
    "            # 这句话是debug用的，如果不满足下面的条件，会直接跳出\n",
    "            assert self.mean[label].shape == (1, trainX.shape[1])\n",
    "            \n",
    "            # 对 x 的每列求方差，使用 keepdims = True 保持维度，存储到 self.var 中，键为 label，值为每列的方差组成的一个二维 np.ndarray\n",
    "            self.var[label] = np.var(x, axis=0, keepdims=True)\n",
    "\n",
    "            # debug\n",
    "            assert self.var[label].shape == (1, trainX.shape[1])\n",
    "            \n",
    "            # 平滑，因为方差在公式的分母部分，我们要加一个很小的数，防止除以0\n",
    "            self.var[label] += 1e-9 * np.var(trainX, axis = 0).max()\n",
    "        \n",
    "    def predict(self, testX):\n",
    "        '''\n",
    "        给定测试样本，预测测试样本的类标记，这里我们要实现化简后的公式\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            testX: np.ndarray, 测试的特征, 维度：(测试样本数, 特征数)\n",
    "    \n",
    "        Returns\n",
    "        ----------\n",
    "            prediction: np.ndarray, 预测结果, 维度：(测试样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 初始化一个空矩阵 results，存储每个样本属于每个类的概率，维度是 (测试样本数，类别数)，每行表示一个样本，每列表示一个特征\n",
    "        results = np.empty((testX.shape[0], len(self.probability_of_y)))\n",
    "        \n",
    "        # 初始化一个列表 labels，按 self.label_mapping 的映射关系存储所有的标记，一会儿会在下面的循环内部完成存储\n",
    "        labels = [0] * len(self.probability_of_y)\n",
    "        \n",
    "        # 遍历当前的类，label为类标记，index为下标，我们将每个样本预测出来的这个 label 的概率，存到 results 中的第 index 列\n",
    "        for label, index in self.label_mapping.items():\n",
    "            \n",
    "            # 先验概率存为 py\n",
    "            py = self.probability_of_y[label]\n",
    "            \n",
    "            # 使用变换后的公式，计算所有特征的条件概率之和，存为sum_of_conditional_probability\n",
    "            # self.var mean per label has vars as shape is len(x)\n",
    "            sum_of_conditional_probability = np.sum(-0.5*(np.log(2*np.pi*self.var[label]) + np.square(testX - self.mean[label])/self.var[label]), axis=1)\n",
    "            # YOUR CODE HERE\n",
    "            \n",
    "            # debug\n",
    "            assert sum_of_conditional_probability.shape == (len(testX), )\n",
    "            \n",
    "            # 使用变换后的公式，将 条件概率 与 log先验概率 相加，存为result，维度应该是 (测试样本数, )\n",
    "            \n",
    "            result = np.log(py) + sum_of_conditional_probability\n",
    "            # YOUR CODE HERE\n",
    "            \n",
    "            # debug\n",
    "            assert result.shape == (len(testX), )\n",
    "            \n",
    "            # 将所有测试样本属于当前这类的概率，存入到results中\n",
    "            results[:, index] = result\n",
    "            \n",
    "            # 将当前的label，按index顺序放入到labels中\n",
    "            labels[index] = label\n",
    "        \n",
    "        # 将labels转换为np.ndarray\n",
    "        np_labels = np.array(labels)\n",
    "        \n",
    "        # 循环结束后，就计算出了给定测试样本，当前样本属于这类的概率的近似值，存放在了results中，每行对应一个样本，每列对应一个特征\n",
    "        # 我们要求每行的最大值对应的下标，也就是求每个样本，概率值最大的那个下标是什么，结果存入max_prob_index中\n",
    "\n",
    "        max_prob_index = np.argmax(results, axis = 1)\n",
    "        \n",
    "        # debug\n",
    "        assert max_prob_index.shape == (len(testX), )\n",
    "        \n",
    "        # 现在得到了每个样本最大概率对应的下标，我们需要把这个下标变成 np_labels 中的标记\n",
    "        prediction = np_labels[max_prob_index]\n",
    "        \n",
    "        # debug\n",
    "        assert prediction.shape == (len(testX), )\n",
    "        \n",
    "        # 返回预测结果\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d6cc0e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('../data/mobile_phone/train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(data[data['sc_w']==0].index)\n",
    "\n",
    "def pre_func(x):\n",
    "    if x==0 or x==1:\n",
    "        return 0\n",
    "    elif x==2 or x==3:\n",
    "        return 1\n",
    "\n",
    "data.price_range = data.price_range.apply(pre_func)\n",
    "features = data.columns\n",
    "features = list(set(features) - {\"price_range\"})\n",
    "X = data[features]\n",
    "y = data.price_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "320ca4a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# your code here\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b89d200a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9491758241758241\n",
      "precision 0.9373368146214099\n",
      "recall_score 0.9650537634408602\n",
      "f1 0.9509933774834438\n"
     ]
    }
   ],
   "source": [
    "model = myGaussianNB()\n",
    "# 计算模型指标\n",
    "model.fit(x_train, y_train)\n",
    "y_hat = model.predict(x_test)\n",
    "print(\"acc\", accuracy_score(y_test, y_hat))\n",
    "print(\"precision\", precision_score(y_test, y_hat))\n",
    "print(\"recall_score\", recall_score(y_test, y_hat))\n",
    "print(\"f1\", f1_score(y_test, y_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e5a14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 实现带有拉普拉斯修正的朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad75b08",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "实验内容：\n",
    "1. 叙述拉普拉斯修正的作用\n",
    "2. 使用给定的数据集\n",
    "3. 给出实现的代码，要有详细的注释\n",
    "4. 给出模型评价指标的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bb7fc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 拉普拉斯修正的具体介绍\n",
    "在训练集中总共的分类数，用 N 表示；di 属性可能的取值数用 Ni 表示，因此原来的先验概率 P(c) 的计算公式由：\n",
    "\n",
    "P(c) = Dc / D\n",
    "\n",
    "被拉普拉斯修正为\n",
    "\n",
    "P(c) = (Dc + 1) / (D + N)\n",
    "\n",
    "类的条件概率由P(xi|c) = Dc,xi / Dc\n",
    "\n",
    "被拉普拉斯修正为\n",
    "\n",
    "P(xi|c) = (Dc,xi + 1) / (Dc + Ni)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7686376",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Balance Scale Data Set 离散特征的三分类数据集\n",
    "#### Attribute Information:\n",
    "\t1. Class Name: 3 (L（左边重）, B（天平平衡）, R（右边重）) \n",
    "\t2. Left-Weight: 5 (1, 2, 3, 4, 5)\n",
    "\t3. Left-Distance: 5 (1, 2, 3, 4, 5)\n",
    "\t4. Right-Weight: 5 (1, 2, 3, 4, 5)\n",
    "\t5. Right-Distance: 5 (1, 2, 3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0acf4961",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 1 1 2]\n",
      " [1 1 1 3]\n",
      " ...\n",
      " [5 5 5 3]\n",
      " [5 5 5 4]\n",
      " [5 5 5 5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt(\"./balance-scale.data\", str, unpack = True)\n",
    "# print(data)\n",
    "#数据处理：分类结果数值化，B->0, L->-1, R->1\n",
    "dicts = {'R': 1, 'L': -1, 'B': 0}\n",
    "# print(dicts['R'])\n",
    "results = [] \n",
    "for i in data:\n",
    "    tmp = []\n",
    "    for j in i:\n",
    "        if j == ',':\n",
    "            continue\n",
    "        if j == 'B' or j == 'R' or j == 'L':\n",
    "            tmp.append(dicts[j])\n",
    "        else:\n",
    "            tmp.append(int(j))\n",
    "    results.append(tmp)\n",
    "data = np.array(results) # 处理后的数据集\n",
    "datax = data[ : , 1 : ]\n",
    "datay = data[ : , 0]\n",
    "print(datax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67dc5328",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((437, 4), (437,), (188, 4), (188,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#划分数据集测试集30%，训练集70%\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(datax, datay, test_size = 0.3, random_state = 32)\n",
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 多分类基线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8936170212765957\n",
      "precision 0.8231104528651759\n",
      "recall_score 0.8936170212765957\n",
      "f1 0.8567486906207958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\python3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 多分类基线\n",
    "clf = GaussianNB()\n",
    "clf.fit(trainX, trainY)\n",
    "y_hat = clf.predict(testX)\n",
    "print(\"acc\", accuracy_score(testY, y_hat))\n",
    "print(\"precision\", precision_score(testY, y_hat, average=\"weighted\"))\n",
    "print(\"recall_score\", recall_score(testY, y_hat, average=\"weighted\"))\n",
    "print(\"f1\", f1_score(testY, y_hat, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc8340ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class myGaussianNB:\n",
    "    '''\n",
    "    处理离散特征的高斯朴素贝叶斯\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化四个字典\n",
    "        self.label_mapping     类标记 与 下标(int)\n",
    "        self.probability_of_y  类标记 与 先验概率(float)\n",
    "        self.probability_of_attributes 类标记 与 每个属性的类条件概率\n",
    "        '''\n",
    "        self.label_mapping = dict()\n",
    "        self.probability_of_y = dict()\n",
    "        self.probability_of_attributes = dict()\n",
    "        \n",
    "    def _clear(self):\n",
    "        '''\n",
    "        为了防止一个实例反复的调用fit方法，我们需要每次调用fit前，将之前学习到的参数删除掉\n",
    "        '''\n",
    "        self.label_mapping.clear()\n",
    "        self.probability_of_y.clear()\n",
    "        self.probability_of_attributes.clear()\n",
    "    \n",
    "    def fit(self, trainX, trainY):\n",
    "        '''\n",
    "        这里，我们要根据trainY内的类标记，针对每类，计算这类的先验概率，以及这类训练样本每个特征的均值和方差\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            trainX: np.ndarray, 训练样本的特征, 维度：(样本数, 特征数)\n",
    "        \n",
    "            trainY: np.ndarray, 训练样本的标记, 维度：(样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 先调用_clear\n",
    "        self._clear()\n",
    "        \n",
    "        # 获取类标记\n",
    "        labels = np.unique(trainY)\n",
    "        # print(\"labels = \", labels)\n",
    "        \n",
    "        # 添加类标记与下标的映射关系\n",
    "        self.label_mapping = {label: index for index, label in enumerate(labels)}\n",
    "        # print(self.label_mapping)\n",
    "        \n",
    "        # 遍历每个类\n",
    "        for label in labels:\n",
    "            \n",
    "            # 取出为label这类的所有训练样本，存为 x\n",
    "\n",
    "            x = trainX[trainY == label, :]\n",
    "            # x = x.to_numpy()\n",
    "            \n",
    "            # 计算先验概率，用 x 的样本个数除以训练样本总个数，存储到 self.probability_of_y 中，键为 label，值为先验概率\n",
    "            self.probability_of_y[label] = (len(x) +1)/ (6 + len(trainY))\n",
    "            \n",
    "            # 计算属性的类条件概率\n",
    "            result = dict()\n",
    "            for index in range(trainX.shape[1]):\n",
    "                tmp = []\n",
    "                for i in range(1, 6): # 每个属性的取值范围：{1, 2, 3, 4, 5}\n",
    "                    total = [t for t in x[ : , index] if t == i]\n",
    "                    # 拉普拉斯修正\n",
    "                    probability = (len(total) + 1) / (6+len(x))\n",
    "\n",
    "                    tmp.append(probability)\n",
    "                result[index] = tmp\n",
    "            self.probability_of_attributes[label] = result\n",
    "            # print('self.probability_of_attributes = ', self.probability_of_attributes[label])\n",
    "            \n",
    "        \n",
    "    def predict(self, testX):\n",
    "        '''\n",
    "        给定测试样本，预测测试样本的类标记，这里我们要实现化简后的公式\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            testX: np.ndarray, 测试的特征, 维度：(测试样本数, 特征数)\n",
    "    \n",
    "        Returns\n",
    "        ----------\n",
    "            prediction: np.ndarray, 预测结果, 维度：(测试样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 初始化一个空矩阵 results，存储每个样本属于每个类的概率，维度是 (测试样本数，类别数)，每行表示一个样本，每列表示一个特征\n",
    "        # testX = testX.to_numpy()\n",
    "        results = np.empty((testX.shape[0], len(self.probability_of_y)))\n",
    "        \n",
    "        # 初始化一个列表 labels，按 self.label_mapping 的映射关系存储所有的标记，一会儿会在下面的循环内部完成存储\n",
    "        labels = [0] * len(self.probability_of_y)\n",
    "        \n",
    "        # 遍历当前的类，label为类标记，index为下标，我们将每个样本预测出来的这个 label 的概率，存到 results 中的第 index 列\n",
    "        for label, index in self.label_mapping.items():\n",
    "            \n",
    "            # print(\"label = \", label)\n",
    "            \n",
    "            # 先验概率存为 py\n",
    "            py = self.probability_of_y[label]\n",
    "            \n",
    "            #  计算测试样本是label类的概率\n",
    "            result = []\n",
    "            for i in range(testX.shape[0]):\n",
    "                tmp = []\n",
    "                for j in range(testX.shape[1]):\n",
    "                    # print('j = ', j, 'testX[i][j] = ', testX[i][j])\n",
    "\n",
    "                    tmp.append(self.probability_of_attributes[label][j][testX[i][j] - 1]) # 细节之处: 越界\n",
    "                result.append(np.sum(np.log(tmp)) + np.log(py)) # 取对数计算防止下溢\n",
    "                \n",
    "            # 存入到results中的第index列中\n",
    "            results[:, index] = result\n",
    "            \n",
    "            # 将当前的label，按index顺序放入到labels中\n",
    "            labels[index] = label\n",
    "        \n",
    "        # 将labels转换为np.ndarray\n",
    "        np_labels = np.array(labels)\n",
    "        \n",
    "        # 循环结束后，就计算出了给定测试样本，当前样本属于这类的概率的近似值，存放在了results中，每行对应一个样本，每列对应一个特征\n",
    "        # 我们要求每行的最大值对应的下标，也就是求每个样本，概率值最大的那个下标是什么，结果存入max_prob_index中\n",
    "        max_prob_index = np.argmax(results, axis = 1)\n",
    "        \n",
    "        # debug\n",
    "        assert max_prob_index.shape == (len(testX), )\n",
    "        \n",
    "        # 现在得到了每个样本最大概率对应的下标，我们需要把这个下标变成 np_labels 中的标记\n",
    "        \n",
    "        prediction = np_labels[max_prob_index]\n",
    "        \n",
    "        # debug\n",
    "        assert prediction.shape == (len(testX), )\n",
    "        \n",
    "        # 返回预测结果\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69050636",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "带拉普拉斯修正的朴素贝叶斯分类器在测试集上的四项指标：\n",
      "acc 0.9042553191489362\n",
      "precision 0.8324468085106383\n",
      "recall_score 0.9042553191489362\n",
      "f1 0.8668015094379055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3_2022.05\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model = myGaussianNB()\n",
    "# your code here\n",
    "print(\"带拉普拉斯修正的朴素贝叶斯分类器在测试集上的四项指标：\")\n",
    "model.fit(trainX, trainY)\n",
    "y_hat = model.predict(testX)\n",
    "print(\"acc\", accuracy_score(testY, y_hat))\n",
    "print(\"precision\", precision_score(testY, y_hat, average=\"weighted\"))\n",
    "print(\"recall_score\", recall_score(testY, y_hat, average=\"weighted\"))\n",
    "print(\"f1\", f1_score(testY, y_hat, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 实验心得 踩坑记录\n",
    "一开始，遇到了四个评价指标全是1.0。\n",
    "认为是代码出错了，最后定位到数据预处理部分出错。feature和label划分出现问题。feature中没有把label去掉，其实是对set的特性不熟。一开始使用的是`set(\"price_range\")`。\n",
    "但是这样是把整个串的所有单个字符做集合，后边修改为`{\"price_range\"}`就是把整个串作为集合的一个元素。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
